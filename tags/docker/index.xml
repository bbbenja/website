<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on Code-Troopers - Vous avez une idée, nous la réalisons</title>
    <link>https://blog-7460a.firebaseapp.com/tags/docker/</link>
    <description>Recent content in Docker on Code-Troopers - Vous avez une idée, nous la réalisons</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>fr-fr</language>
    <lastBuildDate>Wed, 20 Jan 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://blog-7460a.firebaseapp.com/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Jenkins Workflow Plugin</title>
      <link>https://blog-7460a.firebaseapp.com/2016/01/20/jenkinsworkflow</link>
      <pubDate>Wed, 20 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://blog-7460a.firebaseapp.com/2016/01/20/jenkinsworkflow</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Un des points génants lors de l&amp;#8217;utilisation de Jenkins est le coté volatile de la configuration des jobs de builds.
Il est souvent nécessaire de jouer de click-click pour faire la configuration des jobs sur Jenkins et de se reposer sur un plugin permettant de versionner,
autant que possible, les configurations utilisées.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Mais, une fois que vous aurez lu cet article, vous vous rendrez compte que c&amp;#8217;est le passé.
Attention toutefois, cet article parle de Jenkins, de Docker et de Groovy, n&amp;#8217;ayez pas peur, tout est &lt;em&gt;presque&lt;/em&gt; trop simple&amp;#8230;&amp;#8203;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_prérequis_jenkins&#34;&gt;Prérequis Jenkins&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_jenkins_avec_accès_à_docker&#34;&gt;Jenkins avec accès à Docker&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Nous avons l&amp;#8217;habitude d&amp;#8217;utiliser un Jenkins lancé dans un container depuis quelques temps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Nous utilisons l&amp;#8217;image maintenue par &lt;a href=&#34;https://agileek.github.io/&#34;&gt;Michael Bitard&lt;/a&gt; &lt;a href=&#34;https://hub.docker.com/r/agileek/docker-jenkins/&#34;&gt;&lt;code&gt;agileek/docker-jenkins&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Nous lançons cette image en lui fournissant de quoi exécuter le binaire docker client sans soucis :&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run
       -d --restart=&#34;always&#34; --name jenkins
       -u $(id -u):$(getent group docker | cut -d: -f3) &lt;b class=&#34;conum&#34;&gt;(1)&lt;/b&gt;
       -p 8080:8080
       -v /var/jenkins_home:/var/jenkins_home &lt;b class=&#34;conum&#34;&gt;(2)&lt;/b&gt;
       -v $(which docker):/usr/bin/docker &lt;b class=&#34;conum&#34;&gt;(3)&lt;/b&gt;
       -v /var/run/docker.sock:/var/run/docker.sock &lt;b class=&#34;conum&#34;&gt;(4)&lt;/b&gt;
       -v /usr/lib/x86_64-linux-gnu/libapparmor.so.1:/lib/x86_64-linux-gnu/libapparmor.so.1 &lt;b class=&#34;conum&#34;&gt;(5)&lt;/b&gt;
       agileek/docker-jenkins &lt;b class=&#34;conum&#34;&gt;(6)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Le container est lancé avec l&amp;#8217;utilisateur courant et le groupe &lt;code&gt;docker&lt;/code&gt; pour pouvoir accéder au &lt;code&gt;docker.sock&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pour éviter les incohérences de chemin, le chemin racine du jenkins est le même en dehors et dans le container&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Le binaire docker du système est fourni dans l&amp;#8217;image&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Le socket docker est également fourni pour que le client puisse &#34;parler&#34; au démon&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;La bibliotheque apparmor est nécessaire pour le bon fonctionnement de docker client&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_jenkins_workflow_plugin&#34;&gt;Jenkins workflow plugin&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Pour utiliser la suite des éléments, vous aurez besoin des plugins gérant la notion de &lt;em&gt;workflow&lt;/em&gt; dans Jenkins :&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Unresolved directive in &amp;lt;stdin&amp;gt; - include::app/_includes/lightbox.adoc[]&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ensuite, il nous est possible de créer un job de construction de type &lt;em&gt;workflow&lt;/em&gt; :&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Unresolved directive in &amp;lt;stdin&amp;gt; - include::app/_includes/lightbox.adoc[]&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_premier_job_em_workflow_em&#34;&gt;Premier job &lt;em&gt;Workflow&lt;/em&gt;&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ensuite, c&amp;#8217;est là que la magie opère, plutôt que de devoir sélectionner les n-items voulus et remplir chaque étape du build, nous pouvons maintenant le décrire en utilisant du code !
Ainsi, en copiant/collant le script suivant dans la partie idoine, vous devriez avoir un job bien configuré qui marche, du premier coup !&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;def m2Repo = &#39;-v /var/jenkins_home/.m2:/home/jenkins/.m2&#39; //  &lt;b class=&#34;conum&#34;&gt;(1)&lt;/b&gt;
def timezone = &#39;-e TZ=Europe/Paris&#39; // &lt;b class=&#34;conum&#34;&gt;(2)&lt;/b&gt;
docker.image(&#34;codetroopers/jenkins-slave-jdk8-restx&#34;)
    .inside(&#34;${m2Repo} ${timezone}&#34;){ //  &lt;b class=&#34;conum&#34;&gt;(3)&lt;/b&gt;
    git branch: &#39;master&#39;, url: &#39;https://github.com/code-troopers/jenkins-workflow-demo-repo.git&#39; // &lt;b class=&#34;conum&#34;&gt;(4)&lt;/b&gt;
    sh &#34;MAVEN_OPTS=-Dfile.encoding=UTF-8 mvn clean install -B -Ppackage&#34; // &lt;b class=&#34;conum&#34;&gt;(5)&lt;/b&gt;
    step([$class: &#39;ArtifactArchiver&#39;, artifacts: &#39;srv/target/dependency/webapp-runner.jar, srv/target/*.war, run.sh&#39;]) // &lt;b class=&#34;conum&#34;&gt;(6)&lt;/b&gt;
    step([$class: &#39;JUnitResultArchiver&#39;, testResults: &#39;**/target/surefire-reports/TEST-*.xml&#39;]) // &lt;b class=&#34;conum&#34;&gt;(7)&lt;/b&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Partage du dépôt Maven local (pour gagner en temps de build)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Export de la timezone (pour les tests unitaires de l&amp;#8217;exemple)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Démarrage du conteneur de build avec la bonne timezone ainsi que le dépôt partagé&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Clonage des sources&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lancement du build (en forçant l&amp;#8217;UTF-8)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Archivage des produits du build&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Archivage des résultats des tests&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Comme vous pouvez le voir, le script est relativement parlant et permet en plus de s&amp;#8217;affranchir du clickodrome de configuration dans l&amp;#8217;interface de Jenkins !&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Il est intéressant de noter que l&amp;#8217;image Docker qui sert au build est une image personnalisée. Ce n&amp;#8217;est pas parce qu&amp;#8217;elle inclut un quelconque fonctionnement permettant de builder
en utilisant le plugin Workflow. Elle sert de base uniquement car elle met à disposition la partie &lt;code&gt;npm&lt;/code&gt; nécessaire au build de la partie &lt;em&gt;frontend&lt;/em&gt; de l&amp;#8217;application RestX.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_grouper_les_étapes&#34;&gt;Grouper les étapes&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Le plugin workflow permet en plus de grouper les différentes étapes d&amp;#8217;un build pour permettre, par exemple, de le lancer sur plusieurs environnement différents.
Ici nous ajoutons simplement un nom de groupe pour notre étape de build.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;stage &#39;build&#39; // &lt;b class=&#34;conum&#34;&gt;(1)&lt;/b&gt;
    def m2Repo = &#39;-v /var/jenkins_home/.m2:/home/jenkins/.m2&#39;
    def timezone = &#39;-e TZ=Europe/Paris&#39;
    docker.image(&#34;codetroopers/jenkins-slave-jdk8-restx&#34;).inside(&#34;${m2Repo} ${timezone}&#34;){
        git branch: &#39;master&#39;, url: &#39;https://github.com/code-troopers/jenkins-workflow-demo-repo.git&#39;
        sh &#34;MAVEN_OPTS=-Dfile.encoding=UTF-8 mvn clean install -B -Ppackage&#34;
        step([$class: &#39;ArtifactArchiver&#39;, artifacts: &#39;srv/target/dependency/webapp-runner.jar, srv/target/*.war, run.sh&#39;])
        step([$class: &#39;JUnitResultArchiver&#39;, testResults: &#39;**/target/surefire-reports/TEST-*.xml&#39;])
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Étape nommée pour l&amp;#8217;exécution de la construction de l&amp;#8217;application&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_mettre_de_côté_les_fichiers_pour_plus_tard&#34;&gt;Mettre de côté les fichiers pour plus tard&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;La notion de &lt;em&gt;stash&lt;/em&gt; bien connue des utilisateurs de git est également présente.
Elle permet de mettre de côté des fichiers pour les réutiliser à une étape ultérieure du &lt;em&gt;workflow&lt;/em&gt; de build.
Ceci permet d&amp;#8217;éviter l&amp;#8217;archivage de produits du build pour des raisons &#34;techniques&#34;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;stage &#39;build&#39;
    def m2Repo = &#39;-v /var/jenkins_home/.m2:/home/jenkins/.m2&#39;
    def timezone = &#39;-e TZ=Europe/Paris&#39;
    docker.image(&#34;codetroopers/jenkins-slave-jdk8-restx&#34;).inside(&#34;${m2Repo} ${timezone}&#34;){
        git branch: &#39;master&#39;, url: &#39;https://github.com/code-troopers/jenkins-workflow-demo-repo.git&#39;
        sh &#34;MAVEN_OPTS=-Dfile.encoding=UTF-8 mvn clean install -B -Ppackage&#34;
        step([$class: &#39;ArtifactArchiver&#39;, artifacts: &#39;srv/target/dependency/webapp-runner.jar, srv/target/*.war, run.sh&#39;])
        step([$class: &#39;JUnitResultArchiver&#39;, testResults: &#39;**/target/surefire-reports/TEST-*.xml&#39;])
        stash includes: &#39;run.sh,srv/target/dependency/webapp-runner.jar,srv/target/*.war,Dockerfile&#39;, name: &#39;dockerBuild&#39; // &lt;b class=&#34;conum&#34;&gt;(1)&lt;/b&gt;
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Enregistrement d&amp;#8217;une liste de fichiers associée à un nom pour une utilisation ultérieure&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Étape_de_construction_d_une_image_docker&#34;&gt;Étape de construction d&amp;#8217;une image Docker&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;stage &#39;docker&#39; // &lt;b class=&#34;conum&#34;&gt;(1)&lt;/b&gt;
node{ // &lt;b class=&#34;conum&#34;&gt;(2)&lt;/b&gt;
  ws{ // &lt;b class=&#34;conum&#34;&gt;(3)&lt;/b&gt;
    unstash &#39;dockerBuild&#39; // &lt;b class=&#34;conum&#34;&gt;(4)&lt;/b&gt;
    docker.build(&#34;codetroopers/jenkins-workflow-demo:${env.BUILD_ID}&#34;) // &lt;b class=&#34;conum&#34;&gt;(5)&lt;/b&gt;
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Création d&amp;#8217;une nouvelle étape&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Permet de distinguer un ensemble d&amp;#8217;opération de build (peut accepter les labels pour restreindre sur des noeuds)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Déclenche la création d&amp;#8217;un nouveau &lt;em&gt;workspace&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Récupère les fichiers mis de côté sous le nom &lt;code&gt;dockerBuild&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Construction d&amp;#8217;une image docker avec pour tag le numéro de build en cours (&lt;code&gt;$BUILD_ID&lt;/code&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_workflow_et_gestion_multibranche&#34;&gt;Workflow et gestion multibranche&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Dans nos façons de fonctionner qui sont maintenant devenues habituelles, nous utilisons de façon intensives les branches pour isoler nos développements.
Un des points fastidieux est de configurer un nouveau job Jenkins pour chaque branche afin de valider son bon fonctionnement et ne pas se rendre compte trop tard d&amp;#8217;un build au rouge.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Le plugin &#39;Workflow Multibranch&#39; simplifie de façon drastique ce genre de cas, il suffit de rajouter un descripteur de build dans les sources.
Le fichier correspondant est tout simplement appelé &lt;code&gt;Jenkinsfile&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;stage &#39;build&#39;
    def m2Repo = &#39;-v /var/jenkins_home/.m2:/home/jenkins/.m2&#39;
    def timezone = &#39;-e TZ=Europe/Paris&#39;
    docker.image(&#34;codetroopers/jenkins-slave-jdk8-restx&#34;).inside(&#34;${m2Repo} ${timezone}&#34;){
        checkout scm // &lt;b class=&#34;conum&#34;&gt;(1)&lt;/b&gt;
        sh &#34;MAVEN_OPTS=-Dfile.encoding=UTF-8 mvn clean install -B -Ppackage&#34;
        step([$class: &#39;ArtifactArchiver&#39;, artifacts: &#39;srv/target/dependency/webapp-runner.jar, srv/target/*.war, run.sh&#39;])
        step([$class: &#39;JUnitResultArchiver&#39;, testResults: &#39;**/target/surefire-reports/TEST-*.xml&#39;])
        stash includes: &#39;run.sh,srv/target/dependency/webapp-runner.jar,srv/target/*.war,Dockerfile&#39;, name: &#39;dockerBuild&#39;
    }

stage &#39;docker&#39;
node{
  ws{
    unstash &#39;dockerBuild&#39;
    docker.build(&#34;codetroopers/jenkins-workflow-demo:${env.BUILD_ID}&#34;)
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Il faut bien entendu remplacer l&amp;#8217;endroit où nous faisions le git clone pour qu&amp;#8217;il soit dynamique par rapport à ce qu&amp;#8217;on
construit. Le terme &lt;code&gt;checkout scm&lt;/code&gt; permet de s&amp;#8217;assurer de ce fonctionnement.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;L&amp;#8217;intérêt est que chaque branche qui sera buildée n&amp;#8217;aura pas son historique mélangé avec une autre (là où les jobs de validation de Pull Request ont tendance à tout mélanger).
De plus, un changement dans le process de build sera directement versionné.
Il n&amp;#8217;y aura donc pas besoin de penser à éditer le job lors du merge sur &lt;code&gt;master&lt;/code&gt; (on a tous vécu ce genre de situation énervante) !&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_attendre_une_confirmation_utilisateur&#34;&gt;Attendre une confirmation utilisateur&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Un des points intéressant de ce plugin est qu&amp;#8217;il permet la mise en pause des constructions.
Ainsi, il est possible de mettre en pause une construction correspondant à une livraison et de lui faire attendre une validation manuelle par exemple.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;stage &#39;build&#39;
    def m2Repo = &#39;-v /var/jenkins_home/.m2:/home/jenkins/.m2&#39;
    def timezone = &#39;-e TZ=Europe/Paris&#39;
    docker.image(&#34;codetroopers/jenkins-slave-jdk8-restx&#34;).inside(&#34;${m2Repo} ${timezone}&#34;){
        git branch: &#39;master&#39;, url: &#39;https://github.com/code-troopers/jenkins-workflow-demo-repo.git&#39;
        sh &#34;MAVEN_OPTS=-Dfile.encoding=UTF-8 mvn clean install -B -Ppackage&#34;
        step([$class: &#39;ArtifactArchiver&#39;, artifacts: &#39;srv/target/dependency/webapp-runner.jar, srv/target/*.war, run.sh&#39;])
        step([$class: &#39;JUnitResultArchiver&#39;, testResults: &#39;**/target/surefire-reports/TEST-*.xml&#39;])
        stash includes: &#39;run.sh,srv/target/dependency/webapp-runner.jar,srv/target/*.war,Dockerfile&#39;, name: &#39;dockerBuild&#39;
    }

stage &#39;docker&#39;
node{
    ws{
        unstash &#39;dockerBuild&#39;
        def built = docker.build(&#34;codetroopers/jenkins-workflow-demo:${env.BUILD_ID}&#34;)
        input &#39;Is everything ok ? Run app ?&#39; // &lt;b class=&#34;conum&#34;&gt;(1)&lt;/b&gt;
        echo &#34;We can run the docker-compose up here&#34;
        def outcome = input message: &#39;We can even have parameters to answer this question&#39;, parameters: [ // &lt;b class=&#34;conum&#34;&gt;(2)&lt;/b&gt;
            [name: &#39;myChoice&#39;, description: &#39;My choice&#39;, choices: &#39;Choice 1\nChoice 2\nChoice 3&#39;, $class: &#39;ChoiceParameterDefinition&#39;]
        ]
        echo &#34;You have chosen ${outcome}&#34; // &lt;b class=&#34;conum&#34;&gt;(3)&lt;/b&gt;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;colist arabic&#34;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;input&lt;/code&gt; met en pause la construction et permet de continuer ou interrompre celle-ci&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Il est également possible de permettre à l&amp;#8217;utilisateur de faire un choix&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ici la valeur sélectionnée par l&amp;#8217;utilisateur est écrite dans la sortie du build.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;J&amp;#8217;espère que cet article vous donnera l&amp;#8217;envie d&amp;#8217;essayer de rationnaliser un peu plus la configuration de vos job Jenkins en les stockant dans votre SCM&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Navig&#39;Tours : côté serveur</title>
      <link>https://blog-7460a.firebaseapp.com/2016/01/04/navigtours-cote_serveur</link>
      <pubDate>Mon, 04 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://blog-7460a.firebaseapp.com/2016/01/04/navigtours-cote_serveur</guid>
      <description>

&lt;p&gt;Cet article, une fois n&amp;rsquo;est pas coutume, va rentrer un peu plus dans le fonctionnement de la partie serveur mise en place pour &lt;a href=&#34;http://navigtours.com/&#34;&gt;Navig&amp;rsquo;Tours&lt;/a&gt;.
Si vous n&amp;rsquo;êtes pas technique, il risque d&amp;rsquo;être compliqué de le suivre !&lt;/p&gt;

&lt;!-- break --&gt;

&lt;h2 id=&#34;architecture:dad4c2b1f4f43c57ed0806fbc2bfdf56&#34;&gt;Architecture&lt;/h2&gt;

&lt;p&gt;La partie serveur de Navig&amp;rsquo;Tours est en réalité assez simple. Comme dit lors de différentes présentations des membres de Code-Troopers, ce projet est pour nous un moyen de nous amuser lorsque nous nous retrouvons tous les septs.
C&amp;rsquo;est également le projet que nous utilisons pour tester certaines technologies et approches.&lt;/p&gt;

&lt;p&gt;Ainsi, Navig&amp;rsquo;Tours est une application développée en utilisant Java 8, mais rien de forcément très étonnant maintenant. Le côté le plus intéressant est qu&amp;rsquo;elle est en production depuis plus d&amp;rsquo;un an maintenant avec Java 8 !&lt;/p&gt;

&lt;p&gt;Ensuite, nous utilisons l&amp;rsquo;excellent framework RestX pour simplifier notre vie dans la gestion des appels REST, ce qu&amp;rsquo;il nous apporte, entre autres :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;de l&amp;rsquo;injection de dépendances lors de la compilation&lt;/li&gt;
&lt;li&gt;un outillage d&amp;rsquo;administration complet&lt;/li&gt;
&lt;li&gt;une plateforme de test intégrée et de specs nous permettant de documenter facilement l&amp;rsquo;API&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Enfin, pour la partie stockage des données, nous utilisons MongoDB qui nous simplifie la gestion de données en manipulant des données principalement au format JSON (et fournit une bonne gestion de la géolocalisation par coordonnées).&lt;/p&gt;

&lt;h2 id=&#34;du-dev:dad4c2b1f4f43c57ed0806fbc2bfdf56&#34;&gt;Du dev&amp;hellip;&lt;/h2&gt;

&lt;p&gt;Côté dev, nous utilisons notre petit wrapper (&lt;a href=&#34;http://code-troopers.com/2014/12/15/CT_Project_Alias.html&#34;&gt;ct&lt;/a&gt;) pour les tâches classiques qui se charge d&amp;rsquo;effectuer le build ainsi que le run de l&amp;rsquo;application avec ses dépendances.
Le lancement de l&amp;rsquo;application se limite à mettre à disposition un serveur MongoDB ainsi qu&amp;rsquo;à effectuer un &lt;code&gt;java -jar&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;à-la-prod:dad4c2b1f4f43c57ed0806fbc2bfdf56&#34;&gt;À la prod !&lt;/h2&gt;

&lt;p&gt;Historiquement, l&amp;rsquo;application a été déployée sur Heroku dans son plan gratuit en utilisant plusieurs services cibles (pour répartir la charge via l&amp;rsquo;utilisation de plusieurs entrées DNS).&lt;/p&gt;

&lt;p&gt;Mais, suite au changement de tarification d&amp;rsquo;Heroku et notre envie d&amp;rsquo;utiliser Docker sur un vrai projet, nous avons migré l&amp;rsquo;environnement pour utiliser exclusivement Docker.&lt;/p&gt;

&lt;p&gt;Un des intérêts de la transformation que nous avons opéré est que nous sommes également capable de lancer l&amp;rsquo;application très simplement à l&amp;rsquo;aide de descripteurs Docker ainsi que du docker-compose qui décrit les interactions entre nos services.&lt;/p&gt;

&lt;h2 id=&#34;process-de-livraison:dad4c2b1f4f43c57ed0806fbc2bfdf56&#34;&gt;Process de livraison&lt;/h2&gt;

&lt;p&gt;Pour effectuer la livraison de l&amp;rsquo;application, nous sommes passés d&amp;rsquo;un &lt;code&gt;git push&lt;/code&gt; vers heroku à un process impliquant Jenkins dans 3 étapes successives (mais qui s&amp;rsquo;enchaînent automatiquement) :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;construction de l&amp;rsquo;application et archivage dans un &lt;code&gt;tgz&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;copie du tgz produit pour la construction d&amp;rsquo;une image Docker poussée vers notre dépôt interne&lt;/li&gt;
&lt;li&gt;lancement de l&amp;rsquo;application via un &lt;code&gt;docker-compose run -d&lt;/code&gt; sur les machines cibles&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;gestion-du-multi-environnement:dad4c2b1f4f43c57ed0806fbc2bfdf56&#34;&gt;Gestion du multi-environnement&lt;/h2&gt;

&lt;p&gt;Comme toutes les applications d&amp;rsquo;entreprise, nous déployons vers plusieurs environnement afin de valider la bonne tenue de l&amp;rsquo;application et la qualité de nos développements :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;dev / local : poste du développeur&lt;/li&gt;
&lt;li&gt;preprod : version à passer en production&lt;/li&gt;
&lt;li&gt;prod : version actuelle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;À ceci, nous pouvons ajouter plusieurs versions en parallèle pour différentes fonctionnalités et/ou villes (l&amp;rsquo;info exclusive est cachée ici, Navig&amp;rsquo;VotreVille arrive…).
Pour être capable de gérer des déploiements différents nous avons ajouté quelques paramètres à nos scripts de lancement de docker-compose nous permettant de disposer de noms différents par projet pous éviter les problèmes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Monitorer ses conteneurs Docker avec New Relic</title>
      <link>https://blog-7460a.firebaseapp.com/2015/09/30/newrelicdocker</link>
      <pubDate>Wed, 30 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog-7460a.firebaseapp.com/2015/09/30/newrelicdocker</guid>
      <description>

&lt;p&gt;Si vous ne conaissez pas New Relic, vous loupez quelque chose, c&amp;rsquo;est le service indispensable pour monitorer vos serveurs et vos applications. Il est capable d&amp;rsquo;une part de vous remonter les données physiques de vos serveurs (mémoire, cpu, espace disque), et d&amp;rsquo;autre part d&amp;rsquo;analyser les performances de vos applications (de nombreux langages sont disponibles). Il dispose aussi d&amp;rsquo;un système d&amp;rsquo;alerting, facilement configurable. Tous ces services sont disponibles en version gratuite, avec limitation (nombre de jour limité de rétention des données par exemple). Je vous laisse consulter le &lt;a href=&#34;http://www.newrelic.com&#34;&gt;site officiel&lt;/a&gt; pour plus de détail.&lt;/p&gt;

&lt;p&gt;Nous allons seulement parler du service de monitoring des serveurs dans cet article.&lt;/p&gt;

&lt;div style=&#34;float:right;margin:20px&#34;&gt;
    &lt;a href=&#34;https://blog-7460a.firebaseapp.com/images/postNewrelicDocker/new-relic.png&#34; data-lightbox=&#34;group-1&#34; title=&#34;New Relic Logo&#34; class=&#34;inlineBoxes&#34;&gt;
        &lt;img class=&#34;medium&#34; src=&#34;https://blog-7460a.firebaseapp.com/images/postNewrelicDocker/new-relic.png&#34; alt=&#34;New Relic Logo&#34;/&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;div class=&#34;clearfix&#34;&gt;&lt;/div&gt;

&lt;h2 id=&#34;et-docker-dans-tout-ça:bc5e987537bfb69a6aefddb2b5c9b04b&#34;&gt;Et Docker dans tout ça&lt;/h2&gt;

&lt;p&gt;Ce qui est encore plus fort avec le service de monitoring des serveurs de New Relic, c&amp;rsquo;est qu&amp;rsquo;il est capable de comprendre Docker et donc de vous remonter les données par conteneur.&lt;/p&gt;

&lt;div style=&#34;text-align:center;margin:50px&#34;&gt;
    &lt;a href=&#34;https://blog-7460a.firebaseapp.com/images/postNewrelicDocker/screen-newrelic-1.png&#34; data-lightbox=&#34;group-3&#34; title=&#34;Screen 1 New Relic&#34; class=&#34;inlineBoxes&#34;&gt;
        &lt;img class=&#34;medium&#34; src=&#34;https://blog-7460a.firebaseapp.com/images/postNewrelicDocker/screen-newrelic-1.png&#34; alt=&#34;Screen 1 New Relic&#34;/&gt;
    &lt;/a&gt;
    &lt;a href=&#34;https://blog-7460a.firebaseapp.com/images/postNewrelicDocker/screen-newrelic-2.png&#34; data-lightbox=&#34;group-3&#34; title=&#34;Screen 2 New Relic&#34; class=&#34;inlineBoxes&#34;&gt;
        &lt;img class=&#34;medium&#34; src=&#34;https://blog-7460a.firebaseapp.com/images/postNewrelicDocker/screen-newrelic-2.png&#34; alt=&#34;Screen 2 New Relic&#34;/&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;div class=&#34;clearfix&#34;&gt;&lt;/div&gt;

&lt;h2 id=&#34;comment-l-installer:bc5e987537bfb69a6aefddb2b5c9b04b&#34;&gt;Comment l&amp;rsquo;installer&lt;/h2&gt;

&lt;p&gt;Avec Docker bien sûr, il faut au préalable s&amp;rsquo;être créé un compte sur le site New Relic pour obtenir l&amp;rsquo;accès à l&amp;rsquo;interface et pouvoir se créer une clé (à remplacer dans la ligne de commande suivante).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d \
    --privileged=true --name newrelic
    --pid=host \
    --net=host \
    -v /sys:/sys \
    -v /dev:/dev \
    --restart=always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v /var/log:/var/log:rw \
    -e NRSYSMOND_license_key=&amp;lt;KEY&amp;gt; \
    -e NRSYSMOND_logfile=/var/log/nrsysmond.log \
    newrelic/nrsysmond:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vous trouverez toutes les informations &lt;a href=&#34;https://hub.docker.com/r/newrelic/nrsysmond/&#34;&gt;ici&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Owncloud : solution de cloud en 5 min avec Docker</title>
      <link>https://blog-7460a.firebaseapp.com/2015/09/09/ownclouddocker</link>
      <pubDate>Wed, 09 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog-7460a.firebaseapp.com/2015/09/09/ownclouddocker</guid>
      <description>

&lt;p&gt;Que ce soit pour des raisons politique de confidentialité ou des raisons technique, &lt;a href=&#34;https://owncloud.org/&#34;&gt;Owncloud&lt;/a&gt; a énormément de qualités comparé à Dropbox ou Google drive. Déjà car la limite de taille des données est celle du serveur, ensuite car des applications sous linux permettent de synchroniser des dossiers et enfin car il existe une multitude d&amp;rsquo;addons qui permettent de sauvegarder ses mots de passe, jouer de la musique, envoyer des notifs sur Slack etc.&lt;/p&gt;

&lt;p&gt;La mise en production d&amp;rsquo;une instance Owncloud se fait en 5 minutes montre en main, à condition de connaître un minimum Docker.&lt;/p&gt;

&lt;h2 id=&#34;nginx-proxy:be69fc223dd7ef731bed748a197f33c8&#34;&gt;Nginx/proxy&lt;/h2&gt;

&lt;p&gt;Nous allons commencer par une petite digression. Avant quand on avait plusieurs &amp;ldquo;virtual host&amp;rdquo; qui pointaient sur une machine, on mettait un front-end apache et c&amp;rsquo;était plus ou moins la galère. Maintenant, il suffit de lancer cette commande une fois :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --restart=always --name nginx -d -p 80:80 -p 443:443 -v /docker/vhost.d:/etc/nginx/vhost.d:ro -v /var/run/docker.sock:/tmp/docker.sock:ro jwilder/nginx-proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On pourra alors rajouter la variable d&amp;rsquo;environnement &lt;code&gt;VIRTUAL_HOST&lt;/code&gt; à chaque nouvelle image Docker pour qu&amp;rsquo;elle soit directement accessible. Ce qui est magique aussi c&amp;rsquo;est que si on expose un seul port de l&amp;rsquo;image Docker alors il est directement mappé sur le port 80, même si le port n&amp;rsquo;était pas forwardé sur le host. Dernier avantage, si on met deux machines avec le même nom il va s&amp;rsquo;occuper de faire du load balancing tout seul !&lt;/p&gt;

&lt;p&gt;Si jamais la configuration par défaut ne convient pas, il faut rajouter un fichier de configuration dans &lt;code&gt;/docker/vhost.d/&lt;/code&gt;. Dans notre cas nous en avons eu besoin pour permettre d&amp;rsquo;uploader des fichiers plus gros (c&amp;rsquo;est 2 Mo par défaut).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /docker/vhost.d/owncloud.hostname.com
client_max_body_size 100m;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker-compose:be69fc223dd7ef731bed748a197f33c8&#34;&gt;Docker-compose&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/compose/&#34;&gt;Docker-compose&lt;/a&gt; est un outil très pratique pour gérer les options d&amp;rsquo;une image docker. Il faut souvent lancer une image Docker avec des variables d&amp;rsquo;environnement, des liens et des volumes, et quelques semaines plus tard, on ne se souvient plus comment on a lancé les images. Là on n&amp;rsquo;a plus que une seule commande pour gérer toutes les images d&amp;rsquo;un coup et les options sont lisibles facilement.&lt;/p&gt;

&lt;p&gt;Rentrons dans le vif du sujet :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mariaOC:
  image: mariadb
  volumes:
   - /home/owncloud/db:/var/lib/mysql
  environment:
   - MYSQL_ROOT_PASSWORD=passwordRoot
   - MYSQL_USER=owncloud-production
   - MYSQL_DATABASE=owncloud-production
   - MYSQL_PASSWORD=passwordUser
   - TZ=Europe/Paris
owncloud:
  image: jchaney/owncloud
  volumes:
    - /home/owncloud/data:/var/www/owncloud/data
    - /home/owncloud/logs/nginx:/var/log/nginx
    - /home/owncloud/logs/cron:/var/log/cron
    - /etc/ssl/certs/ssl-cert-snakeoil.pem:/etc/ssl/certs/ssl-cert-snakeoil.pem:ro
    - /etc/ssl/private/ssl-cert-snakeoil.key:/etc/ssl/private/ssl-cert-snakeoil.key:ro
  environment:
    - VIRTUAL_HOST=owncloud.hostname.com
    - MYSQL_ROOT_PASSWORD=passwordRoot
    - MYSQL_USER=owncloud-production
    - MYSQL_DATABASE=owncloud-production
    - MYSQL_PASSWORD=passwordUser
    - TZ=Europe/Paris
    - OWNCLOUD_IN_ROOTPATH=1
    - OWNCLOUD_SERVER_NAME=owncloud.hostname.com
    - SSL_CERT=/etc/ssl/certs/ssl-cert-snakeoil.pem
    - SSL_KEY=/etc/ssl/private/ssl-cert-snakeoil.key
  links:
    - mariaOC:db
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Voici le fichier docker-compose.yml utilisé. On définit une image de &lt;a href=&#34;https://mariadb.org/&#34;&gt;MariaDB&lt;/a&gt; pour laquelle on spécifie un volume qui va recevoir les données et différentes variables d&amp;rsquo;environnements dont les noms sont assez explicite.
Puis une image owncloud avec des volumes pour les fichiers que l&amp;rsquo;on va sauvegarder, les logs et la clé SSL. Un lien avec la base de donnée MariaDB et quelques variables d&amp;rsquo;environnements, là encore les noms sont suffisamment explicite.&lt;/p&gt;

&lt;p&gt;Une fois les variables modifiées selon notre volonté, il faut lancer les commandes &lt;code&gt;docker-compose build&lt;/code&gt; suivi de &lt;code&gt;compose-docker up -d&lt;/code&gt; et aller sur owncloud.hostname.com pour finir l&amp;rsquo;installation.&lt;/p&gt;

&lt;p&gt;L&amp;rsquo;article est déjà fini, comme je le disais, ça se fait en un rien de temps. Mais si cela a été aussi rapide, c&amp;rsquo;est parce que Owncloud a une image très bien faîtes donc merci Josh de l&amp;rsquo;avoir mise à disposition &lt;a href=&#34;https://github.com/jchaney/owncloud&#34;&gt;https://github.com/jchaney/owncloud&lt;/a&gt;&lt;/p&gt;

&lt;div style=&#34;text-align:center;margin-bottom:50px&#34;&gt;
    &lt;a href=&#34;https://blog-7460a.firebaseapp.com/images/postOwncloudDocker/owncloud.png&#34; data-lightbox=&#34;group-1&#34; title=&#34;Owncloud site et appli&#34; class=&#34;inlineBoxes&#34;&gt;
        &lt;img class=&#34;medium&#34; src=&#34;https://blog-7460a.firebaseapp.com/images/postOwncloudDocker/owncloud.png&#34; alt=&#34;Owncloud site et appli&#34;/&gt;
    &lt;/a&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Installer votre dépot privé Docker</title>
      <link>https://blog-7460a.firebaseapp.com/2015/06/25/installdockerregistry</link>
      <pubDate>Thu, 25 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://blog-7460a.firebaseapp.com/2015/06/25/installdockerregistry</guid>
      <description>

&lt;p&gt;Petit à petit chez Code-Troopers, nous migrons tous nos développements pour utiliser Docker.
Cela fait quelque temps que nous l&amp;rsquo;utilisons pour des projets &amp;ldquo;public&amp;rdquo;, auquel cas le registry public Docker est largement suffisant (et immédiat à utiliser).&lt;/p&gt;

&lt;p&gt;En revanche, nous commençons à migrer nos applications de production également vers Docker, et nous ne pouvons pas utiliser le mode public du registry public.
Nous nous sommes donc mis à déployer un dépôt privé, authentifié par utilisateur / mot de passe.&lt;/p&gt;

&lt;p&gt;La procédure n&amp;rsquo;est pas très complexe, mais cette opération reste une bonne opportunité d&amp;rsquo;écrire un article à ce sujet (les articles en français n&amp;rsquo;étant pas légion).&lt;/p&gt;

&lt;h2 id=&#34;step-by-step:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Step by step&lt;/h2&gt;

&lt;p&gt;Il faut créer une entrée DNS pour votre service.&lt;/p&gt;

&lt;p&gt;Puis nous allons utiliser l&amp;rsquo;image Docker avec nginx pour l&amp;rsquo;authentification &lt;a href=&#34;https://github.com/MarvAmBass/docker-nginx-registry-proxy&#34;&gt;docker-nginx-registry-proxy&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;informations-d-identification:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Informations d&amp;rsquo;identification&lt;/h2&gt;

&lt;p&gt;Pour les étapes suivantes, placez vous dans le répertoire de votre choix pour stocker les fichiers (dans ce cas nous sommes dans &lt;code&gt;/srv/registry-config&lt;/code&gt;)&lt;/p&gt;

&lt;h3 id=&#34;génération-du-certificat:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Génération du certificat&lt;/h3&gt;

&lt;p&gt;Pensez à bien renseigner le FQDN DNS lors de la demande de Common Name pour le certificat.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openssl genrsa -out ca.key 4096
openssl req -new -x509 -days 1826 -key ca.key -out ca.crt
openssl genrsa -out ia.key 4096
openssl req -new -key key.pem -out ia.csr #this is where you need to fill your FQDN
openssl x509 -req -days 730 -in ia.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out cert.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;génération-des-mots-de-passes-basic-auth:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Génération des mots de passes basic auth&lt;/h3&gt;

&lt;p&gt;En utilisant un container docker qui embarque htpasswd vous pourrez générer facilement le fichier nécessaire :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --rm -ti -v $(pwd):/tmp dgageot/htpasswd -c /tmp/docker-registry.htpasswd $MONUSER
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;démarrage-du-registry:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Démarrage du registry&lt;/h2&gt;

&lt;p&gt;Les images seront stockées dans le répertoire &lt;code&gt;/srv/registry&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir /srv/registry
docker run -d --restart=always --name registry -v /srv/docker-registry:/registry -e &amp;quot;SETTINGS_FLAVOR=local&amp;quot; -e &amp;quot;STORAGE_PATH=/registry&amp;quot; registry
docker run -d --restart=always -p 443:443 -v /srv/registry-config:/etc/nginx/external --link registry:registry --name nginx-registry-proxy marvambass/nginx-registry-proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuration-d-une-machine-cliente:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Configuration d&amp;rsquo;une machine cliente&lt;/h2&gt;

&lt;h3 id=&#34;importer-le-certificat-racine:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Importer le certificat racine&lt;/h3&gt;

&lt;p&gt;Il faut importer le certificat racine dans la liste des certificats reconnus&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo -s
mkdir -p /etc/docker/certs.d/$FQDN
cp ca.crt /etc/docker/certs.d/$FQDN/

mkdir -p /usr/local/share/ca-certificates/docker-ct
cp ca.crt /usr/local/share/ca-certificates/docker-ct/
update-ca-certificates-
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pour vérifier que tout fonctionne comme attendu, vous pouvez voir si votre certificat ressort bien dans la commande suivante :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;awk -v cmd=&#39;openssl x509 -noout -subject&#39; &#39; /BEGIN/{close(cmd)};{print | cmd}&#39; &amp;lt; /etc/ssl/certs/ca-certificates.crt | grep $(VOTRE IDENTIFIANT)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vous serez également certainement amené à redémarrer vos daemon docker (de chacune des machines)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;systemctl stop docker
systemctl start docker
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;identification-sur-le-dépot:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Identification sur le dépot&lt;/h3&gt;

&lt;p&gt;Une fois que toutes ces étapes sont effectuées, normalement votre dépot est prêt à être utilisé.&lt;/p&gt;

&lt;p&gt;Il vous faut cependant en première étape vous identifier à l&amp;rsquo;aide du couple utilisateur / mot de passe créé lors de l&amp;rsquo;installation :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker login https://mondepotdocker.tld
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ceci aura pour effet de créer un fichier &lt;code&gt;~/.dockercfg&lt;/code&gt; vous permettant d&amp;rsquo;accéder aux commandes suivantes sans avoir besoin de retaper vos identifiants.&lt;/p&gt;

&lt;h2 id=&#34;utilisation-du-dépôt:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Utilisation du dépôt&lt;/h2&gt;

&lt;p&gt;Une fois la machine cliente configurée, vous pouvez simplement utiliser le dépot en préfixant les noms de vos images par l&amp;rsquo;URL du dépôt.
Par exemple, pour push/pull l&amp;rsquo;image de monapplication la commande suivante fera l&amp;rsquo;affaire :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker push mondepotdocker.tld/monapplication:v1.0.0
docker pull mondepotdocker.tld/monapplication:v1.0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;utilisation-avec-docker-compose:5ccf6384c70e5ed97658dbf0e91e8805&#34;&gt;Utilisation avec docker-compose&lt;/h3&gt;

&lt;p&gt;Si vous utilisez docker-compose, il se peut que vous ayiez des soucis avec le certificat autosigné et/ou avec l&amp;rsquo;authentification.&lt;/p&gt;

&lt;p&gt;Pour contourner la vérification du certificat, vous pouvez simplement lancer &lt;code&gt;docker-compose&lt;/code&gt; avec le flag &lt;code&gt;--allow-insecure-ssl&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Pour ce qui est de l&amp;rsquo;authentification, une astuce simple pour contourner les problèmes de ce genre est de faire un &lt;code&gt;docker pull&lt;/code&gt; manuellement au préalable (le scripter depuis le fichier compose.yml n&amp;rsquo;est pas trop difficile).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>